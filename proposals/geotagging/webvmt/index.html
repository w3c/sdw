<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <title>WebVMT: The Web Video Map Tracks Format</title>
    <script
     src='https://www.w3.org/Tools/respec/respec-w3c'
     class='remove'></script>
    <script class='remove'>
      var respecConfig = {
        specStatus: "ED",
        editors: [{
          name: "Rob Smith",
          mailto: "rob.smith@awayteam.co.uk",
          company: "Away Team Software Ltd",
          companyURL: "http://www.awayteam.co.uk",
          w3cid: 105524
        }],
        charterDisclosureURI: "https://www.w3.org/2017/sdwig/charter.html#patentpolicy",
        edDraftURI: "https://w3c.github.io/sdw/proposals/geotagging/webvmt/",
        shortName: "webvmt",
        group: "sdw",
        wgPublicList: "public-sdwig",
        github: "https://github.com/w3c/sdw"
      };
    </script>
  </head>
  <body>
    <section id='abstract'>
      <p>
        This specification defines WebVMT, the Web Video Map Tracks format, which is an enabling technology whose main use is for marking up external map track resources in connection with the HTML &lt;track&gt; element. WebVMT files provide map presentation and annotation synchronised to video content, including animation support, and more generally any form of geolocation data that is time-aligned with audio or video content.
      </p>
    </section>
    <section id='sotd'>
      <p>
        This document is an explanatory specification, intended to communicate and develop the draft WebVMT format through discussion with user communities.
      </p>
    </section>
    <section class='informative' id='usecases'>
      <h2>Use Cases</h2>
      <p>
        Example scenarios in which WebVMT can add significant value, with a list of identified benefits.
      </p>
      <section id='mountainrescue'>
        <h2>Coastguard/Mountain Rescue</h2>
        <p>
          A missing person is reported to the rescue services, who deploy a drone to search inaccessible areas of coastline or moorland for their target. The drone relays back a live video stream from its camera and geolocation data from its GPS receiver to a remote human operator who is piloting it.
        </p>
        <p>
          As the search continues, the operator spots a target on the video feed and can instantly call up an electronic map, synchronised to the video, which has been automatically following the drone’s position and plotting its ground track. The display gives the operator immediate context for the video, and allows them to override the automatic map control and zoom in to pinpoint the target’s precise location from the features visible in the video and on the map/satellite view. They mark the location and then zoom out to assess the surrounding terrain and advise the recovery team of the best approach to the target. For example, the terrain may dictate very different approach routes if either the person has twisted their ankle at the top of a cliff, or has fallen and is lying at the bottom of the same cliff, though the co-ordinates are almost identical in both cases.
        </p>
        <p>
          The operator has been able to make important decisions quickly, which may be life critical, and deploy recovery resources effectively.
        </p>
        <ul class='note' title='Benefits'>
          <li>Rapid decision making;</li>
          <li>Effective resource deployment.</li>
        </ul>
      </section>
      <section id='areasurvey'>
        <h2>Area Survey</h2>
        <p>
          A survey drone is equipped with a camera which records an image of the ground directly below it. The pilot is a remote human operator, tasked with surveying a defined area from particular height in order to capture the required data.
        </p>
        <p>
          As the survey progresses, geometric shapes are automatically added to the map to represent areas which have been included. Once the drone has finished its sweep, the operator can quickly confirm whether the required area has been completely covered. If any areas have been missed, the pilot can use the map to navigate and make additional passes to fill the gaps, before returning to base.
        </p>
        <p>
          Adding map track (VMT) files to the survey archive provides a geospatial index to the videos, allowing a particular geographic location to be found more rapidly by virtue of their small file size. Online video archives can be indexed more quickly using this web-friendly format.
        </p>
        <p>
          The operator has been easily able to verify the quality of their own work and correct any errors, saving time and additional effort in redeployment. Video footage has been indexed by geolocation rapidly and in a search-engine-friendly format.
        </p>
        <ul class='note' title='Benefits'>
          <li>Autonomous quality assurance;</li>
          <li>Cost saving;</li>
          <li>Rapid archive indexing for search engines.</li>
        </ul>
      </section>
      <section id='outdoortrails'>
        <h2>Outdoor Trails</h2>
        <p>
          An outdoor sportsperson, e.g. snowboarder or cyclist, is equipped with a helmet camera and/or mobile phone to record video footage and GPS data. They set off to find new challenges and practice their skills, e.g. off-piste or on mountain trails, and discover new routes and areas that they would like to explore in future, chatting to the camera as they go. Afterwards, they upload the video to share their experience with the online community, so others can quickly identify locations of particularly interesting sections of the featured trail. Using the synchronised map view in their browser, community members can easily see where they need to go in order to try it for themselves.
        </p>
        <p>
          The operator has been able to fully engage in their sporting activity, without making any written notes, while simultaneously recording the details needed to guide others to the same locations. Their changing location over time can also be used to calculate speed and distance information, which can be displayed alongside the footage.
        </p>
        <ul class='note' title='Benefits'>
          <li>Non-invasive capture;</li>
          <li>Information sharing;</li>
          <li>Speed and distance calculation.</li>
        </ul>
      </section>
      <section id='tvsportscoverage'>
        <h2>TV Sports Coverage</h2>
        <p>
          A TV production company is covering a sports event that takes place over a large area, e.g. rallying, road cycling or sailing, using a number of mobile video devices including competitor cams, e.g. dash cams or helmet cams, and drones to provide shots of inaccessible areas, e.g. remote terrain or over water.
        </p>
        <p>
          Feeds from all the cameras are streamed to the production control room, where their geolocation data are combined on a map showing the locations of every competitor and camera, each labelled for easy identification. The live map enables the director to quickly choose the best shot and anticipate where and when to deploy their drone cameras to catch competitors at critical locations on the course as the competition develops in real time.
        </p>
        <p>
          Multiple operators can function concurrently, both autonomously and under central direction. Mobile assets can be monitored and deployed from an operations centre to provide optimum coverage of the developing live event.
        </p>
        <ul class='note' title='Benefits'>
          <li>Multiple mobile video devices;</li>
          <li>Real time asset management.</li>
        </ul>
      </section>
      <section id='proxyexplorer'>
        <h2>Proxy Explorer</h2>
        <p>
          Important details of a remote area have been captured on video. It is not possible to revisit the location for safety reasons or because it has physically changed in the intervening time. Footage can be retrospectively geotagged against a concurrent map to allow the viewer to better interpret and identify features seen in the footage. Explanatory annotations can be added to the video-map track to help future viewers' understanding and aggregate the collective analysis.
        </p>
        <p>
          Multiple operators can contribute their observations to provide a group analysis, iteratively adding new details and discarding out-of-date information. Experts can offer insight about filmed locations, which would otherwise be inaccessible to them.
        </p>
        <ul class='note' title='Benefits'>
          <li>Remote analysis of inaccessible locations;</li>
          <li>Knowledge aggregation and sharing for archive footage.</li>
        </ul>
      </section>
      <section id='treasurehunt'>
        <h2>Treasure Hunt</h2>
        <p>
          A TV production company designs a new game show which involves competitors searching for targets across a wide area, with an operations centre remotely monitoring their progress and providing updates. Competitors are equipped with body-worn video or helmet cameras to relay footage of their view.
        </p>
        <p>
          Geolocation context allow central operators to better understand the participants' actions and to remotely direct them more efficiently. Competitors' positions can displayed to the TV audience on annotated 2D- or 3D-maps for clearer presentation.
        </p>
        <ul class='note' title='Benefits'>
          <li>Speed and distance calculation;</li>
          <li>Knowledge aggregation and sharing for real-time footage.</li>
        </ul>
      </section>
      <section id='swarmmonitoring'>
        <h2>Swarm Monitoring</h2>
        <p>
          A swarm of drones is deployed to perform a task, and their operations are monitored centrally. Geolocation details of the swarm are automatically collated and broadcast to the drone pilots, showing the locations of all the drones and each is circled with a suitable safety zone to warn their operators in case two units find themselves flying in close proximity.
        </p>
        <p>
          Pilots are safely able to operate either autonomously or under the direction of central control. Extra zonal information can be added to the operators' maps to show the outer perimeter of their operating area and warn of fixed aerial hazards, e.g. a radio mast, or transient hazards, e.g. a helicopter.
        </p>
        <ul class='note' title='Benefits'>
          <li>Static and dynamic hazard indication;</li>
          <li>Central swarm monitoring;</li>
          <li>Autonomous swarm monitoring.</li>
        </ul>
      </section>
      <section id='crisisresponse'>
        <h2>Crisis Response</h2>
        <p>
          Disaster strikes, e.g. hurricane, tsunami, and emergency response teams are deployed to the affected area. However, it is difficult to verify which problems people are facing, what resources would help them and exactly where these events are occurring. Maps are unreliable as the infrastructure has been damaged, though people on the ground have the relevant knowledge if it could be reliably recorded and shared.
        </p>
        <p>
          Anyone with a basic smartphone could video events with reliable geospatial data, as GPS receivers can operate without the need for a mobile phone signal by using satellite data, to accurately document the problems they face. Even if the cell network is not operational, this information can be physically delivered to crisis coordinators to notify them of the issues that need to be addressed, including an accurate location in a common format. Crisis events can be reliably recorded, knowledge can be shared and aggregated, and relief resources can be accurately targeted and deployed to the correct locations.
        </p>
        <ul class='note' title='Benefits'>
          <li>Reliable dispersed information gathering and sharing;</li>
          <li>Accurate resource deployment.</li>
        </ul>
      </section>
      <section id='fastestlap'>
        <h2>Fastest Lap</h2>
        <p>
          An amateur racer attempts to set a fastest lap time in a vehicle equipped with a dashcam. The film can be reviewed with details of location and vehicle telemetry to analyse its performance, and that of the driver, to identify where improvements can be made. The ideal racing line can be determined and measured against the actual line taken, and optimum braking points can be established by suggesting and testing corrections.
        </p>
        <p>
          Driver's commentary can be used to identify performance issues along with vehicle audio response, e.g. engine tone and tyres, for comparison with telemetry data to rapidly iterate testing using community analysis tools. Results can be shared online in a common format to display metrics and to demonstrate veracity.
        </p>
        <ul class='note' title='Benefits'>
          <li>Data synchronisation with video and audio;</li>
          <li>Motion analysis using community tools.</li>
        </ul>
      </section>
      <section id='policeevidence'>
        <h2>Police Evidence</h2>
        <p>
          A web-based police system is established to allow dashcam video evidence of driving offences to be submitted digitally by members of the public who have witnessed them. Detectives are able to identify the time and vehicles involved directly from the uploaded footage, and accurately determine the location at which the incident occurred from the digital metadata included.
        </p>
        <p>
          Its ability to accept open format data also makes the system available to cyclists and pedestrians who can record video with location on their helmet cameras and smartphones respectively, providing wider access to the service beyond the dashcam community. Metadata, e.g. location, from different video manufacturers is often recorded in mutually-incompatible formats, but video-map track support enables synchronised location (and other) data to be extracted from recordings using manufacturers' or community tools, without affecting source video integrity, and submitted to the police system in a common format, significantly reducing development costs.
        </p>
        <p>
          Officers have been able to identify incident locations quickly and accurately, without sacrificing evidence integrity. The online service has been made available to a wider audience of drivers, cyclists and pedestrians, without incurring additional development costs.
        </p>
        <ul class='note' title='Benefits'>
          <li>Accurate location with evidence integrity preserved;</li>
          <li>Development costs reduced;</li>
          <li>Service extended to a wider audience.</li>
        </ul>
      </section>
      <section id='areamonitoring'>
        <h2>Area Monitoring</h2>
        <p>
          An area of interest is monitored operationally by a collection of different mobile video devices, e.g. drones, body-worn video, helicopter, etc. Video footage, possibly in different formats, is added to an archive with location (and other) metadata in a common format which forms a time-location index suitable for rapid parsing by a web crawler. Users can submit online queries to search by location and return a time-ordered sequence of video frame stills captured within a radial distance of the chosen location.
        </p>
        <p>
          Video archives can be quickly indexed using a common metadata format regardless of video encoding, e.g. MPEG, WebM, OGG, and video files are only accessed in case of a positive search result, which reduces bandwidth in comparison to embedded metadata. Linked files also allow different security permissions to be applied to the crawling and querying processes, so an AI algorithm can be authorised to read metadata without being able to access image content if there are security concerns over data privacy, e.g. illicit facial recognition.
        </p>
        <ul class='note' title='Benefits'>
          <li>Homogenized video metadata from disparate sources;</li>
          <li>Reduced search bandwidth;</li>
          <li>Structured security support;</li>
          <li>Web search engine compatible.</li>
        </ul>
        <aside class='example' title='Remote Maintenance'>
          Visually monitor inaccessible assets, e.g. off-shore wind turbines, using autonomous drones to create a historical video archive that enables remote expert diagnosis of operational issues.
        </aside>
        <aside class='example' title='Flood Monitoring'>
          Aggregate video footage from disparate sources to create a historical video archive that allows water levels to be monitored at different locations over time to help predict flooding.
        </aside>
      </section>
      <section id='vehiclecollision'>
        <h2>Vehicle Collision</h2>
        <p>
          Dashcam footage is searched to automatically identify vehicle collisions from impact acceleration profiles recorded in video metadata. Dashcam manufacturers typically embed metadata in an unpublished format and provide a proprietary video player to allow users to display it. Exporting embedded metadata to a linked file in a web-friendly format enables searchable video archive data to be shared quickly and easily, without affecting evidence integrity, and to be accessed through a common web interface.
        </p>
        <p>
          Vehicles can be automatically monitored using a low-cost dashcam and web-based tools to ensure that collisions are accurately recorded by drivers and that commercial vehicles remain safe and undamaged. Interoperability means that users are not limited to a particular dashcam brand and can share evidence with insurers and the police in a common format without damaging its integrity.
        </p>
        <ul class='note' title='Benefits'>
          <li>Accurate vehicle collision detection;</li>
          <li>Common format for data sharing;</li>
          <li>Web search support;</li>
          <li>Evidence integrity preserved.</li>
        </ul>
        <aside class='example' title='Motor Insurance'>
          Automatically identify vehicle collisions in dashcam footage to provide forensic evidence for a police investigation or motor insurance claim.
        </aside>
      </section>
      <section id='goldentutorial'>
        <h2>Golden Tutorial</h2>
        <p>
          Augmented reality (AR) software is used to control assets or view content in situ at a particular location. For example, nearby street lights can be switched off or on by a service engineer for maintenance purposes, or an architect can see how their structural design integrates with the surrounding landscape at its proposed location before any building work has started.
        </p>
        <p>
          Video footage can be recorded with location, camera orientation and other metadata so AR overlays be generated on demand. Such recordings can be used to demonstrate how AR content is displayed and controlled in order to educate users with a 'golden tutorial', to provide 'proof of action' as evidence of work done for auditing purposes, or to create example data for AR software testing and debugging.
        </p>
        <ul class='note' title='Benefits'>
          <li>Accurate AR video and data recording;</li>
          <li>Improved AR software development.</li>
        </ul>
      </section>
      <section id='virtualguide'>
        <h2>Virtual Guide</h2>
        <p>
          A user triggers an audio track which provides guidance about the local area or instruction for a known object, e.g. Web of Things (WoT) device at that location. The audio timeline is synchronised with events that can display AR content, control WoT devices and display points of interest on a map which provide guidance with real world context by highlighting places or objects of interest and showing possible actions.
        </p>
        <p>
          Users can be guided by a virtual assistant through an area of interest or sequence of actions augmented with AR/VR and WoT devices to visualise events and by an annotated map or model to provide additional geospatial context. Greater insight is given to the user by showing detailed views of the location on a map or internal structure of the identified object using a virtual model.
        </p>
        <ul class='note' title='Benefits'>
          <li>Contextual guidance provided in situ;</li>
          <li>Concurrent operation with AR/VR video;</li>
          <li>Integration with Web of Things.</li>
        </ul>
        <aside class='example' title='Historic Site Guide'>
          Provide an audio guide to visitors at a historic site which is triggered by proximity to a location of interest and synchonised with AR content which reconstructs past buildings and events. The same concept could be implemented in VR to allow remote users to explore the site.
        </aside>
        <aside class='example' title='Medical Tool'>
          Allow a patient to describe their symptoms using AR, e.g. by pointing to a painful area on their own body, which is also modelled as a 'map' to show internal features and display a treatment guide, including any WoT medical devices.
        </aside>
        <aside class='example' title='On-Site Maintenance'>
          Guide a user to control and maintain assets, e.g. infrastructure or machinery. A maintenance engineer could switch off an individual street light in order to replace the bulb using an AR control on the WoT lamppost and request procedural guidance for that particular variant. A farm worker could be guided through operational and diagnostic procedures for agricultural equipment to help rectify a fault while on site.
        </aside>
      </section>
    </section>
    <section class='informative' id='stateoftheart'>
      <h2>State of the Art</h2>
      <p>
        No standard format currently exists by which web browsers can synchronise geolocation data with video. Though many browser-supported formats exist to present the two data streams separately, e.g. MPEG for video and GPX for geolocation, there is no viable synchronisation mechanism for video playback time with geolocation information.
      </p>
      <section id='currentsolutions'>
        <h2>Current Solutions</h2>
        <p>
          Material Exchange Format (MXF) was developed by the Society of Motion Picture and Television Engineers (SMPTE) to synchronise metadata, including geolocation, with audio and video streams using a register of key-length-value (KLV) triples. The breadth of its scope has resulted in interoperability issues, as different vendors implement different parts of the standard, and has produced implementations from high-profile companies which are mutually incompatible. KLVs can also be embedded within MPEG files, though this does not address the synchronisation issue for other web video formats such as WebM.
        </p>
        <p>
          Video camera manufacturers have taken various approaches, resulting in a number of non-standard solutions including embedding geolocation data within the MPEG metadata stream in disparate formats, e.g. Go-Pro Metadata Format (GPMF), or recording a separate geolocation file in a proprietary format alongside the associated video file. From a hardware perspective, a few high-end cameras provide geotagging out of the box and all require an add-on device to support this feature.
        </p>
        <p>
          Geospatial data are not currently accessible in the video Document Object Model (DOM) in HTML nor via video playback APIs in smartphones, e.g. Android, though their host devices are typically equipped with both a video camera and Global Navigation Satellite System (GNSS) receiver capable of capturing the required information.
        </p>
        <p>
          In sharp contrast, still photos have a well-established geotagging standard called Exif, which was published by the Japan Electronic Industries Development Association (JEIDA) in 1995 and defines a metadata tag to embed geolocation data within TIFF and JPEG images. This is widely supported by manufacturers of photographic equipment and software worldwide, including low-end smartphones, making this feature cheap and accessible to the public.
        </p>
      </section>
      <section id='growingrequirements'>
        <h2>Growing Requirements</h2>
        <p>
          Historically, there has been no requirement for a comparable video standard, but the urgency for such a standard is growing fast due to the emerging markets for 'mobile video devices,' e.g. drones, dashcams, body-worn video and helmet cameras, as well as the rise in high-quality video and geolocation support in the global smartphone market.
        </p>
      </section>
      <section id='accessiblestandard'>
        <h2>Accessible Standard Opportunity</h2>
        <p>
          Using current W3C recommendations, it is possible for a competent programmer to synchronise video-geolocation 'metadata' with a &lt;video&gt; element using a &lt;track&gt; child element. However, this is a non-trivial development task which requires an understanding of the video DOM events and Javascript file handling, making it inaccessible to the vast majority of web users. In addition, video map tracks are a clearly identified metadata subclass, which could be isolated in a similar way to video text tracks.
        </p>
        <p>
          Establishing a standard file format would allow interoperability and information sharing between the public, the emergency services, police and other mobile video device users, e.g. drone pilots, giving cheaper and easier access to this important source of information. If web browsers supported video geotagging natively using this file format, it would also become accessible to most web users. Current low-end smartphones already provide suitable hardware to concurrently capture video and geolocation streams, which would make this technology easily accessible to the general public, and encourage the user and developer communities to grow rapidly.
        </p>
      </section>
    </section>
    <section class='informative' id='proposedsolution'>
      <h2>Proposed Solution</h2>
      <p>
        This proposal constitutes a lightweight markup language to synchronise video with geolocation data for display on electronic maps, e.g. OpenStreetMaps. It offers presentational control of the map display, e.g. pan and zoom, and annotation to highlight map features to the viewer, e.g. markers and labels.
      </p>
      <p>
        WebVMT (Web Video Map Tracks) format is intended for marking up external map track resources, and its main use is for files synchronising video content with an annotated map presentation. Ideas have been borrowed from existing W3C formats, including WebVTT's HTML binding and its block and cue structures, and SVG's approach to drawing and animation, in order to display output on an electronic map.
      </p>
      <p>
        The format mimics WebVTT's structure and syntax for video synchronisation, with cue details listed in an accessible text-based file linked to the <code>&lt;video&gt;</code> DOM element by a child <code>&lt;track&gt;</code> element in an HTML document.
      </p>
      <pre class='nohighlight example' title='WebVMT Basic HTML'>
&lt;!doctype html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;WebVMT Basic Example&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;!-- Video display --&gt;
    &lt;video controls width="640" height="360"&gt;
      &lt;source src="video.mp4" type="video/mp4"&gt;
      &lt;track src="maptrack.vmt" kind="metadata" for="vmt-map" tileurl="https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png?key=VALID_OSM_KEY"&gt;
      Your browser does not support the video tag.
    &lt;/video&gt;
    &lt;!-- Map display --&gt;
    &lt;div id="vmt-map" style="height: 360px; width:640px;"&gt;&lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
      </pre>
      <p>
        The VMT (Video Map Track) format file, e.g. maptrack.vmt, contains the map cues associated with the video, e.g. video.mp4.
      </p>
      <p class='ednote'>
        The meaning of <code>for</code> and <code>tileurl</code> attributes for user agents is an open question. Initial solutions can be built using Javascript, with existing map libraries such as Leaflet, though the vision is that future user agents will handle map rendering in the longer term.
      </p>
      <section id='mapcues'>
        <h2>Map Cues</h2>
        <p>
          Map cues display their payload between a start time and end time. The end cue time may be omitted to signify the end time of the video, which may be unknown in the case of streamed video.
        </p>
        <section id='helloworld'>
          <h2>Hello World</h2>
          <p>
            Here is a sample VMT file with a cue highlighting Tower Bridge in London on a static map.
          </p>
          <pre class='nohighlight example' title='Tower Bridge VMT'>
WEBVMT

MEDIA
url:TowerBridge.mp4
mimetype:video/mp4

MAP
lat:51.506,lng:-0.076
rad:250

00:00:02.000 --&gt; 00:00:05.000
{ "moveto":
  { "lat": 51.504362, "lng": -0.076153 }
}
{ "lineto":
  { "lat": 51.506646, "lng": -0.074651 }
}
          </pre>
        </section>
        <section id='mappresentation'>
          <h2>Map Presentation</h2>
          <p>
            Cues also allow dynamic presentation to pan and zoom the map. This example focusses attention on the Tower of London.
          </p>
          <p>
            Cues without end times are displayed until the end of the video.
          </p>
          <pre class='nohighlight example' title='Tower of London VMT'>
WEBVMT

MEDIA
url:../movies/TowerOfLondon.webm
mimetype:video/webm

MAP
lat:51.162,lng:-0.143
rad:20000

00:00:03.000 --&gt;
{ "panto":
  { "lat": 51.508, "lng": -0.077, "end": "00:00:05.000" }
}

00:00:06.000 --&gt;
{ "zoom":
  { "rad": 250 }
}
          </pre>
        </section>
      </section>
      <section id='comments'>
        <h2>Comments</h2>
        <p>
          Comments are blocks that are preceded by a blank line, start with the word <code>NOTE</code> (followed by a space or newline), and end at the first blank line.
        </p>
        <section id='commentblock'>
          <h2>Comment Block</h2>
          <p>
            Comment block format is identical to <a data-cite='WEBVTT#introduction-comments'>WebVTT</a>.
          </p>
          <pre class='nohighlight example' title='Tower Landmarks VMT'>
WEBVMT

NOTE Associated video

MEDIA
url:/home/myuser/movies/TowerLandmarks.ogg
mimetype:video/ogg

NOTE Map config

MAP
lat:51.506,lng:-0.076
rad:500

NOTE Tower Bridge

00:00:01.000 --&gt; 00:00:05.000
{ "moveto":
  { "lat": 51.504362, "lng": -0.076153 }
}
{ "lineto":
  { "lat": 51.506646, "lng": -0.074651 }
}

NOTE City Hall

00:00:02.000 --&gt;
{ "circle":
  { "lat": 51.504789, "lng": -0.078642, "rad": 20 }
}

NOTE Tower Of London
This line is also part of the comment

00:00:03.000 --&gt; 00:00:04.000
{ "polygon":
  { "points":
    [ { "lat": 51.507193, "lng": -0.074844 },
      { "lat": 51.508756, "lng": -0.074716 },
      { "lat": 51.509036, "lng": -0.075638 },
      { "lat": 51.508929, "lng": -0.077162 },
      { "lat": 51.507727, "lng": -0.077848 },
      { "lat": 51.507220, "lng": -0.075767 }
    ]
  }
}
          </pre>
        </section>
      </section>
      <section id='styling'>
        <h2>Styling</h2>
        <p>
          Display style is controlled by CSS, which may be embedded in HTML or within the VMT file.
        </p>
        <section id='cssstylehtml'>
          <h2>CSS Style in HTML</h2>
          <p>
            In this example, an HTML page has a CSS style sheet in a <code>&lt;style&gt;</code> element that styles map cues for the video, e.g. drawing lines in red.
          </p>
          <pre class='nohighlight example' title='Style Within HTML'>
&lt;!doctype html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;WebVMT Style Example&lt;/title&gt;
    &lt;style&gt;
      video::cue-map {
        stroke-color: red;
        stroke-opacity: 0.9;
      }
    &lt;/style&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;video controls width="640" height="360"&gt;
      &lt;source src="video.mp4" type="video/mp4"&gt;
      &lt;track src="maptrack.vmt" kind="metadata" for="vmt-map" tileurl="https://api2.ordnancesurvey.co.uk/mapping_api/v1/service/zxy/EPSG%3A3857/Outdoor%203857/\{z}/{x}/{y}.png?key=VALID_OS_KEY"&gt;
      Your browser does not support the video tag.
    &lt;/video&gt;
    &lt;div id="vmt-map" style="height: 360px; width:640px;"&gt;&lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
          </pre>
        </section>
        <section id='cssstyleblock'>
          <h2>CSS Style Block</h2>
          <p>
            Style block format is similar to <a data-cite='WEBVTT#styling'>WebVTT</a>.
          </p>
          <p>
            CSS style sheets can also be embedded in WebVMT files themselves. Style blocks are placed after any headers but before the first cue, and start with the word <code>STYLE</code>.
          </p>
          <p>
            Comment blocks can be interleaved with style blocks.
          </p>
          <pre class='nohighlight example' title='Greenwich Meridian VMT'>
WEBVMT

MEDIA
url:http://example.com/movies/Greenwich.mp4
mimetype:video/mp4

MAP
lat:51.478,lng:-0.001
rad:50

STYLE
::cue-map {
  stroke-color: red;
}

NOTE Comments are allowed between style blocks

STYLE
::cue-map {
  stroke-opacity: 0.9;
}

NOTE Prime Meridian marker

00:00:00.000 --&gt;
{ "moveto":
  { "lat":51.477901, "lng": -0.001466 }
}
{ "lineto":
  { "lat":51.477946, "lng": -0.001466 }
}

NOTE Style blocks may not appear after the first cue
          </pre>
        </section>
      </section>
      <section id='animation'>
        <h2>Animation</h2>
        <p>
          Map annotations may be animated using an <code>animate</code> command, in a similar way to the <code>&lt;animate&gt;</code> element in <a data-cite='SVG11' data-no-xref=''>SVG</a>.
        </p>
        <p>
          Paths have additional properties to other annotations including a unique identifier, and an animation which can be controlled separately for distance calculation purposes.
        </p>
        <section id='animatedpath'>
          <h2>Animated Path</h2>
          <p>
            A path typically identifies a mobile camera's route, which is defined by a <code>moveto</code> command followed by a sequence of <code>lineto</code> commands, and may include multiple discrete segments separated by <code>moveto</code> commands.
          </p>
          <p>
            A path may be assigned an identifier using the <code>path</code> attribute to discriminate between and uniquely identify multiple paths. Distinct paths may be styled in different ways, e.g. colour, with separate speed and distance calculations performed during playback.
          </p>
          <p>
            In this example, an animated path is traced from London to Brighton:
          </p>
          <pre class='nohighlight example' title='London to Brighton VMT'>
WEBVMT

NOTE Associated video

MEDIA
url:LondonBrighton.mp4
mimetype:video/mp4

NOTE Map config

MAP
lat:51.1618,lng:-0.1428
rad:20000

NOTE London overview

00:00:01.000 --&gt;
{ "panto":
  { "lat": 51.4952, "lng": -0.1441 }
}

00:00:02.000 --&gt;
{ "zoom":
  { "rad": 10000 }
}

NOTE From London Victoria...

00:00:03.000 --&gt;
{ "panto":
  { "lat": 50.830553, "lng": -0.141706, "end": "00:00:25.000" }
}
{ "moveto":
  { "lat": 51.494477, "lng": -0.144753, "path": "cam1" }
}
{ "lineto":
  { "lat": 51.155958, "lng": -0.16089, "path": "cam1", "end": "00:00:10.000" }
}

NOTE ...via Gatwick Airport...

00:00:10.000 --&gt;
{ "lineto":
  { "lat": 50.830553, "lng": -0.141706, "path": "cam1", "end": "00:00:25.000" }
}

NOTE ...to Brighton (at 00:00:25.000)

00:00:27.000 --&gt;
{ "zoom":
  { "rad": 20000 }
}
          </pre>
        </section>
        <section id='animatedannotation'>
          <h2>Animated Annotation</h2>
          <p>
            This example tracks a drone with a circular 10-metre safety zone around it.
          </p>
          <pre class='nohighlight example' title='Safe Drone VMT'>
WEBVMT

NOTE Associated video

MEDIA
url:SafeDrone.mp4
mimetype:video/mp4

NOTE Map config

MAP
lat:51.0130,lng:-0.0015
rad:1000

NOTE Drone starts at (51.0130, -0.0015)

00:00:05.000 --&gt;
{ "panto":
  { "lat": 51.0070, "lng": -0.0020, "end": "00:00:25.000" }
}
{ "moveto":
  { "lat": 51.0130, "lng": -0.0015, "path": "drone1" }
}
{ "lineto":
  { "lat": 51.0090, "lng": -0.0017, "path": "drone1",
    "end": "00:00:10.000" }
}

NOTE Safety zone

00:00:05.000 --&gt; 00:00:10.000
{ "circle":
  { "lat": 51.0130, "lng": -0.0015, "rad": 10,
    "animate":
    [ { "name": "lat", "to": 51.0090, "end": "00:00:10.000" },
      { "name": "lng", "to": -0.0017, "end": "00:00:10.000" }
    ]
  }
}

NOTE Drone arrives at (51.0090, -0.0017)

00:00:10.000 --&gt;
{ "lineto":
  { "lat": 51.0070, "lng": -0.0020, "path": "drone1", "end": "00:00:25.000" }
}
{ "circle":
  { "lat": 51.0090, "lng": -0.0017, "rad": 10,
    "animate":
    [ { "name": "lat", "to": 51.0070, "end": "00:00:25.000" },
      { "name": "lng", "to": -0.0020, "end": "00:00:25.000" }
    ]
  }
}

NOTE Drone ends at (51.0070, -0.0020)
          </pre>
        </section>
      </section>
      <section id='youtubeintegration'>
        <h2>YouTube Integration</h2>
        <p>
          Embedded YouTube content can be displayed using an <code>&lt;iframe&gt;</code> element, specifying the unique 10-character content identifier for the posted video, using the official <a href="https://developers.google.com/youtube/iframe_api_reference">YouTube IFrame API</a> with the Javascript API enabled.
        </p>

        <section id='helloyoutube'>
          <h2>Hello YouTube</h2>
          <p>
            A child <code>&lt;track&gt;</code> pseudo-element within the <code>&lt;iframe&gt;</code> links it with WebVMT using the same syntax as for the <code>&lt;video&gt;</code> DOM element.
          </p>
          <pre class='nohighlight example' title='WebVMT YouTube HTML'>
&lt;!doctype html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;WebVMT YouTube Example&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;!-- Video display --&gt;
    &lt;iframe src="http://www.youtube.com/embed/YOUTUBE_VIDEO_ID?enablejsapi=1" width="640" height="360" frameborder="0"&gt;
      &lt;track src="maptrack.vmt" kind="metadata" for="vmt-map" tileurl="mapbox://styles/mapbox/streets-v9"&gt;
    &lt;/iframe&gt;
    &lt;!-- Map display --&gt;
    &lt;div id="vmt-map" style="height: 360px; width:640px;"&gt;&lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
          </pre>
          <p>
            Note that the <code>&lt;track&gt;</code> pseudo-element is actually replaced by the <code>&lt;iframe&gt;</code> content when the page is loaded.
          </p>
          <p>
            The <code>url</code> in the <code>MEDIA</code> block should match the <code>src</code> attribute of the <code>&lt;iframe&gt;</code> element without the query.
          </p>
          <pre class='nohighlight example' title='YouTube VMT Fragment'>
WEBVMT

NOTE Associated YouTube video

MEDIA
url:http://www.youtube.com/embed/YOUTUBE_VIDEO_ID
mimetype:video/mp4
          </pre>
        </section>
      </section>
    </section>
    <section class='informative' id='datamodel'>
      <h2>Data Model</h2>
      <p class='ednote'>
        The data model of WebVMT consists of four key elements: the linked media file, the video viewport, cues, and the map viewport. The linked media file contains audio or video data with which cues are synchronised. The video viewport is the rendering area for video output. Cues are containers consisting of a set of metadata lines. The map viewport is the rendering area for metadata output, for example graphical annotations overlaid on an online map.
      </p>
      <section class='informative' id='overview'>
        <h2>Overview</h2>
        <p>
          The WebVMT file is a container file for chunks of data that are time-aligned with a video or audio resource. It can therefore be regarded as a serialisation format for time-aligned data.
        </p>
        <p>
          A WebVMT file starts with a header and then contains a series of data blocks. If a data block has a start time, it is called a WebVMT cue. A comment is another kind of data block.
        </p>
        <p>
          A WebVMT file carries cues which are identified as <a data-cite='HTML51/semantics-embedded-content.html#attr-valuedef-track-kind-metadata'>metadata</a> and specified in the <a data-cite='HTML51/semantics-embedded-content.html#element-attrdef-track-kind'>kind</a> attribute of the <a data-cite='HTML51/semantics-embedded-content.html#the-track-element'>track</a> element in the <a data-cite='HTML51' data-no-xref=''>HTML</a> specification.
        </p>
        <p>
          The data kind of a WebVMT file is externally specified, such as in a HTML file’s <a data-cite='HTML51/semantics-embedded-content.html#the-track-element'>track</a> element. The environment is responsible for interpreting the data correctly.
        </p>
        <p>
          A <a>WebVMT cue</a> is rendered as an overlay on top of the map viewport.
        </p>
      </section>
      <section id='webvmtcues'>
        <h2>WebVMT Cues</h2>
        <p>
          A <dfn>WebVMT cue</dfn> is a <a data-cite='HTML51/semantics-embedded-content.html#cue'>text track cue</a> with an optional <a data-cite='HTML51/semantics-embedded-content.html#text-track-cue-end-time'>end time</a> and that additionally consists of the following:
        </p>
        <dl>
          <dt>
            A <dfn>cue text</dfn>
          </dt>
          <dd>
            The raw text of the cue which is interpreted as time-aligned metadata, and rules for its interpretation.
          </dd>
        </dl>
        <p class='note' title='End Time Omission'>
          A <a>WebVMT cue</a> without an end time indicates that the cue end time is unbounded, for example during live streaming when the time of the next data sample is unknown or when the duration of the media is unknown.
        </p>
      </section>
      <section id='webvmtmap'>
        <h2>WebVMT Map</h2>
        <p>
          A <dfn>WebVMT map</dfn> is the map viewport and provides a rendering area for <a>WebVMT cue</a>s.
        </p>
        <p>
          A <a>WebVMT map</a> consists of:
        </p>
        <dl>
          <dt>
            A <dfn>map center latitude</dfn>
          </dt>
          <dd>
            The latitude of the location at the center of the map.
          </dd>
          <dt>
            A <dfn>map center longitude</dfn>
          </dt>
          <dd>
            The longitude of the location at the center of the map.
          </dd>
          <dt>
            A <dfn>map zoom radius</dfn>
          </dt>
          <dd>
            The radius in metres of the minimum area visible from the center of the map.
          </dd>
          <dt>
            A <dfn>map object</dfn>
          </dt>
          <dd>
            The control interface object for the map.
          </dd>
          <p class='note' title='Map Control Object'>
            The precise format of the <a>map object</a> control interface is implementation dependent, for example the OpenLayers API.
          </p>
        </dl>
      </section>
      <section id='webvmtmediafile'>
        <h2>WebVMT Media</h2>
        <p>
          A <dfn>WebVMT media</dfn> is the linked media data with which <a>WebVMT cue</a>s are synchronised, for example audio or video.
        </p>
        <p class='note' title='Search Engines'>
          A <a>WebVMT media</a> enables a web crawler to rapidly search media metadata by providing sufficient information to construct a time-metadata index of the linked media file without opening it. Search engine data throughput is reduced as only matching media files selected by the user need be read, and non-matching media files are not accessed at all. Care should be taken to maintain <a>WebVMT media</a> details correctly, for example when a media file is renamed.
        </p>
        <p>
          A <a>WebVMT media</a> consists of:
        </p>
        <dl>
          <dt>
            A <dfn>media URL</dfn>
          </dt>
          <dd>
            The URL of the linked media file.
          </dd>
          <p class='note' title='Media URL'>
            A null <a>media URL</a> indicates that no linked media file exists.
          </p>
          <dt>
            A <dfn>media MIME type</dfn>
          </dt>
          <dd>
            The MIME type of the linked media file.
          </dd>
          <p class='note' title='Media MIME Type'>
            A null <a>media MIME type</a> indicates that no linked media file exists.
          </p>
          <dt>
            A <dfn>media start time</dfn>
          </dt>
          <dd>
            The global time and date at which the linked media file begins.
          </dd>
          <p class='note' title='Media Start Time'>
            The <a>media start time</a> allows multiple <a>WebVMT file</a>s to be aggregated. A null <a>media start time</a> indicates that no start time is associated, for example in the case of an animation.
          </p>
          <dt>
            A <dfn>media path</dfn>
          </dt>
          <dd>
            The path identifier which uniquely identifies the moving object capturing the linked media file.
          </dd>
          <p class='note' title='Media Path'>
            A null <a>media path</a> indicates that no moving object is associated, for example when no linked media file exists.
          </p>
        </dl>
      </section>
      <section id='commandstructures'>
        <h2>WebVMT Command Structures</h2>
        <p>
          A <dfn>WebVMT command</dfn> is an instruction to display WebVMT metadata content.
        </p>
        <p>
          A <a>WebVMT command</a> consists of one of the following components:
          <ul>
            <li>
              A <a>WebVMT map control</a> command;
            </li>
            <li>
              A <a>WebVMT shape annotation</a> command;
            </li>
            <li>
              A <a>WebVMT path</a>.
            </li>
          </ul>
        </p>
        <p class='note' title='Command Execution Order'>
          <a>WebVMT command</a>s are executed in order from first to last in the <a>WebVMT file</a>.
        </p>
        <section id='mapcontrols'>
          <h2>Map Controls</h2>
          <p>
            A <dfn>WebVMT map control</dfn> command controls map presentation.
          </p>
          <p>
            A <a>WebVMT map control</a> command consists of one of the following components:
          </p>
          <ul>
            <li>
              A <a>WebVMT pan</a> command.
            </li>
            <li>
              A <a>WebVMT zoom</a> command.
            </li>
          </ul>
          <p>
            A <dfn>WebVMT pan</dfn> is a command to set the center location of the map.
          </p>
          <p>
            A <a>WebVMT pan</a> consists of:
          </p>
          <dl>
            <dt>
              A <dfn>pan latitude</dfn>
            </dt>
            <dd>
              The latitude in degrees of the map center.
            </dd>
            <dt>
              A <dfn>pan longitude</dfn>
            </dt>
            <dd>
              The longitude in degrees of the map center.
            </dd>
            <dt>
              A <dfn>pan end time</dfn>
            </dt>
            <dd>
              The time at which the new map center is reached.
            </dd>
            <dd>
              The pan end time may be defined as an absolute value, or calculated relative to the cue start time using a duration.
            </dd>
          </dl>
          <p>
            A <dfn>WebVMT zoom</dfn> is a command to set the level of detail of the map.
          </p>
          <p>
            A <a>WebVMT zoom</a> consists of:
          </p>
          <dl>
            <dt>
              A <dfn>zoom radius</dfn>
            </dt>
            <dd>
              The radius in metres of the minimum area visible from the center of the map.
            </dd>
          </dl>
        </section>
        <section id='shapeannotations'>
          <h2>Shape Annotations</h2>
          <p>
            A <dfn>WebVMT shape annotation</dfn> command annotates a shaped area to a map overlay.
          </p>
          <p>
            A <a>WebVMT shape annotation</a> command consists of one of the following components:
          </p>
          <ul>
            <li>
              A <a>WebVMT circle</a> command.
            </li>
            <li>
              A <a>WebVMT polygon</a> command.
            </li>
          </ul>
          <p>
            A <dfn>WebVMT circle</dfn> is a command to annotate a circular area to the map.
          </p>
          <p>
            A <a>WebVMT circle</a> consists of:
          </p>
          <dl>
            <dt>
              A <dfn>circle latitude</dfn>
            </dt>
            <dd>
              The latitude in degrees of the circle center.
            </dd>
            <dt>
              A <dfn>circle longitude</dfn>
            </dt>
            <dd>
              The longitude in degrees of the circle center.
            </dd>
            <dt>
              A <dfn>circle radius</dfn>
            </dt>
            <dd>
              The radius in metres of the circle.
            </dd>
          </dl>
          <p>
            A <dfn>WebVMT polygon</dfn> is a command to annotate a polygonal area to the map.
          </p>
          <p>
            A <a>WebVMT polygon</a> consists of:
          </p>
          <dl>
            <dt>
              A list of <dfn>WebVMT location</dfn>s defining the polygon vertices.
            </dt>
            <dd>
              Vertex locations are listed sequentially around the perimeter of the polygon. The last vertex should not repeat the value of the first, as this is implicit.
            </dd>
          </dl>
          <p>
            A <a>WebVMT location</a> consists of:
          </p>
          <dl>
            <dt>
              A <dfn>location latitude</dfn>
            </dt>
            <dd>
              The latitude in degrees of the location.
            </dd>
            <dt>
              A <dfn>location longitude</dfn>
            </dt>
            <dd>
              The longitude in degrees of the location.
            </dd>
          </dl>
          <p class='note' title='Co-ordinate Reference System'>
            Location information is provided in terms of World Geodetic System coordinates, WGS84.
          </p>
        </section>
        <section id='paths'>
          <h2>Paths</h2>
          <p>
            A <dfn>WebVMT path</dfn> consists of all the <a>path segment</a>s with the same unique <dfn>path identifier</dfn>.
          </p>
          <p>
            A <dfn>path segment</dfn> describes the trajectory of the identified object moving through the mapped space.
          </p>
          <p>
            A <a>path segment</a> consists of the following components, in the order given:
          </p>
          <ol>
            <li>
              One <a>WebVMT move</a> command;
            </li>
            <li>
              Zero or more <a>WebVMT line</a> commands.
            </li>
          </ol>
          <p>
            A <dfn>WebVMT move</dfn> is a command to set the start location of the <a>path segment</a>.
          </p>
          <p>
            A <a>WebVMT move</a> consists of:
          </p>
          <dl>
            <dt>
              A <a>path identifier</a>
            </dt>
            <dd>
              The identifier shared by all the <a>path segment</a>s in the <a>WebVMT path</a>.
            </dd>
            <dd>
              By default, the path identifier is set to null.
            </dd>
            <dt>
              A <dfn>segment start latitude</dfn>
            </dt>
            <dd>
              The latitude in degrees of the path segment start.
            </dd>
            <dt>
              A <dfn>segment start longitude</dfn>
            </dt>
            <dd>
              The longitude in degrees of the path segment start.
            </dd>
          </dl>
          <p>
            A <dfn>WebVMT line</dfn> is a command to set the end location of the <a>path segment</a>.
          </p>
          <p>
            A <a>WebVMT line</a> consists of:
          </p>
          <dl>
            <dt>
              A <a>path identifier</a>
            </dt>
            <dd>
              The identifier shared by all the <a>path segment</a>s in the <a>WebVMT path</a>.
            </dd>
            <dd>
              By default, the path identifier is set to null.
            </dd>
            <dt>
              A <dfn>segment end latitude</dfn>
            </dt>
            <dd>
              The latitude in degrees of the path segment end.
            </dd>
            <dt>
              A <dfn>segment end longitude</dfn>
            </dt>
            <dd>
              The longitude in degrees of the path segment end.
            </dd>
            <dt>
              A <dfn>segment end time</dfn>
            </dt>
            <dd>
              The time at which the path segment end location is reached.
            </dd>
            <dd>
              The segment end time may be defined as an absolute value, or calculated relative to the cue start time using a duration.
            </dd>
          </dl>
          <p class="note" title="Path Interpolation">
            A <a>WebVMT line</a> is a straight line between two locations. The trajectory of the moving object can be linearly interpolated between the cue start time and the segment end time.
          </p>
        </section>
        <section id='animations'>
          <h2>Animations</h2>
          <p>
            A <dfn>WebVMT animation</dfn> changes an object attribute from a start value to an end value over a given time.
          </p>
          <p>
            A <a>WebVMT animation</a> consists of:
          </p>
          <dl>
            <dt>
              An <dfn>animation object</dfn>
            </dt>
            <dd>
              The parent object of the attribute.
            </dd>
            <dt>
              An <dfn>animation attribute</dfn>
            </dt>
            <dd>
              The attribute of the object to change.
            </dd>
            <dt>
              An <dfn>animation start value</dfn>
            </dt>
            <dd>
              The initial value of the attribute.
            </dd>
            <dt>
              An <dfn>animation end value</dfn>
            </dt>
            <dd>
              The final value of the attribute.
            </dd>
            <dt>
              An <dfn>animation start time</dfn>
            </dt>
            <dd>
              The time at which to begin changing the attribute.
            </dd>
            <dt>
              An <dfn>animation end time</dfn>
            </dt>
            <dd>
              The time at which to finish changing the attribute.
            </dd>
            <dd>
              The animation end time may be defined as an absolute value, or calculated relative to the animation start time using a duration.
            </dd>
          </dl>
        </section>
      </section>
    </section>
    <section id='syntax'>
      <h2>Syntax</h2>
      <section id='webvmtfilestructure'>
        <h2>WebVMT File Structure</h2>
        <p>
          A <dfn>WebVMT file</dfn> must consist of a <a>WebVMT file body</a> encoded as <a data-cite='RFC3629' data-no-xref=''>UTF-8</a> and labeled with the <a data-cite='HTML51/infrastructure.html#mime-type'>MIME type</a> <code>text/vmt</code>.
        </p>
        <p>
          A <dfn>WebVMT file body</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              An optional U+FEFF BYTE ORDER MARK (BOM) character.
            </li>
            <li>
              The string "<code>WEBVMT</code>" (U+0057 LATIN CAPITAL LETTER W, U+0045 LATIN CAPITAL LETTER E, U+0042 LATIN CAPITAL LETTER B, U+0056 LATIN CAPITAL LETTER V, U+004D LATIN CAPITAL LETTER M, U+0054 LATIN CAPITAL LETTER T).
            </li>
            <li>
              Optionally, either a U+0020 SPACE character or a U+0009 CHARACTER TABULATION (tab) character followed by any number of characters that are not U+000A LINE FEED (LF) or U+000D CARRIAGE RETURN (CR) characters.
            </li>
            <li>
              Two or more <a>WebVMT line terminator</a>s to terminate the line with the file magic and separate it from the rest of the body.
            </li>
            <li>
              The following components, in any order, separated from each other by one or more <a>WebVMT line terminator</a>s.
            </li>
            <ul>
              <li>
                A <a>WebVMT media definition block</a>.
              </li>
              <li>
                A <a>WebVMT map initialisation block</a>.
              </li>
              <li>
                Zero or more <a>WebVMT style block</a>s and <a>WebVMT comment block</a>s separated from each other by one or more <a>WebVMT line terminator</a>s.
              </li>
            </ul>
            <li>
              Zero or more <a>WebVMT line terminator</a>s.
            </li>
            <li>
              Zero or more <a>WebVMT cue block</a>s and <a>WebVMT comment block</a>s separated from each other by one or more <a>WebVMT line terminator</a>s.
            </li>
            <li>
              Zero or more <a>WebVMT line terminator</a>s.
            </li>
          </ol>
        </p>
        <p>
          A <dfn>WebVMT line terminator</dfn> consists of one of the following:
          <ul>
            <li>
              A U+000D CARRIAGE RETURN U+000A LINE FEED (CRLF) character pair.
            </li>
            <li>
              A single U+000A LINE FEED (LF) character.
            </li>
            <li>
              A single U+000D CARRIAGE RETURN (CR) character.
            </li>
          </ul>
        </p>
        <p>
          A <dfn>WebVMT media definition block</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              The string "<code>MEDIA</code>" (U+004D LATIN CAPITAL LETTER M, U+0045 LATIN CAPITAL LETTER E, U+0044 LATIN CAPITAL LETTER D, U+0049 LATIN CAPITAL LETTER I, U+0041 LATIN CAPITAL LETTER A).
            </li>
            <li>
              Zero or more U+0020 SPACE characters or U+0009 CHARACTER TABULATION (tab) characters.
            </li>
            <li>
              A <a>WebVMT line terminator</a>.
            </li>
            <li>
              A <a>WebVMT media settings list</a>.
            </li>
            <li>
              A <a>WebVMT line terminator</a>.
            </li>
          </ol>
        </p>
        <p>
          A <dfn>WebVMT map initialisation block</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              The string "<code>MAP</code>" (U+004D LATIN CAPITAL LETTER M, U+0041 LATIN CAPITAL LETTER A, U+0050 LATIN CAPITAL LETTER P).
            </li>
            <li>
              Zero or more U+0020 SPACE characters or U+0009 CHARACTER TABULATION (tab) characters.
            </li>
            <li>
              A <a>WebVMT line terminator</a>.
            </li>
            <li>
              A <a>WebVMT map settings list</a>.
            </li>
            <li>
              A <a>WebVMT line terminator</a>.
            </li>
          </ol>
        </p>
        <p class='note' title='Map Initialisation'>
          The <a>WebVMT map initialisation block</a> defines the state of the <a>WebVMT map</a> before any <a>WebVMT cue</a>s are active.
        </p>
        <p>
          A <dfn>WebVMT style block</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              The string "<code>STYLE</code>" (U+0053 LATIN CAPITAL LETTER S, U+0054 LATIN CAPITAL LETTER T, U+0059 LATIN CAPITAL LETTER Y, U+004C LATIN CAPITAL LETTER L, U+0045 LATIN CAPITAL LETTER E).
            </li>
            <li>
              Zero or more U+0020 SPACE characters or U+0009 CHARACTER TABULATION (tab) characters.
            </li>
            <li>
              A <a>WebVMT line terminator</a>.
            </li>
            <li>
              Any sequence of zero or more characters other than U+000A LINE FEED (LF) characters and U+000D CARRIAGE RETURN (CR) characters, each optionally separated from the next by a <a>WebVMT line terminator</a>, except that the entire resulting string must not contain the substring "<code>--></code>" (U+002D HYPHEN-MINUS, U+002D HYPHEN-MINUS, U+003E GREATER-THAN SIGN). The string represents a CSS style sheet; the requirements given in the relevant <a data-cite="CSS22" data-no-xref=''>CSS</a> specifications apply.
            </li>
            <li>
              A <a>WebVMT line terminator</a>.
            </li>
          </ol>
        </p>
        <p>
          A <dfn>WebVMT cue block</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              Optionally, a <a>WebVMT cue identifier</a> followed by a <a>WebVMT line terminator</a>.
            </li>
            <li>
              <a>WebVMT cue timings</a>.
            <li>
              Zero or more U+0020 SPACE characters or U+0009 CHARACTER TABULATION (tab) characters.
            </li>
            <li>
              A <a>WebVMT line terminator</a>.
            </li>
            <li>
              The <dfn>WebVMT cue payload</dfn> consists of a <a>WebVMT metadata text</a>, but must not contain the substring "<code>--></code>" (U+002D HYPHEN-MINUS, U+002D HYPHEN-MINUS, U+003E GREATER-THAN SIGN).
            </li>
            <li>
              A <a>WebVMT line terminator</a>.
            </li>
          </ol>
        </p>
        <p class='note' title='Cues'>
          A <a>WebVMT cue block</a> corresponds to one piece of time-aligned data in the <a>WebVMT file</a>. The <a>WebVMT cue payload</a> is the data associated with the <a>WebVMT cue</a>.
        </p>
        <p>
          A <dfn>WebVMT cue identifier</dfn> is any sequence of one or more characters not containing the substring "<code>--></code>" (U+002D HYPHEN-MINUS, U+002D HYPHEN-MINUS, U+003E GREATER-THAN SIGN), nor containing any U+000A LINE FEED (LF) characters or U+000D CARRIAGE RETURN (CR) characters.
        </p>
        <p>
          A <a>WebVMT cue identifier</a> must be unique amongst all the <a>WebVMT cue identifier</a>s of all <a>WebVMT cue</a>s of a <a>WebVMT file</a>.
        </p>
        <p class='note' title='Cue References'>
          A <a>WebVMT cue identifier</a> can be used to reference a specific cue, for example from script or CSS.
        </p>
        <p>
          The <dfn>WebVMT cue timings</dfn> part of a <a>WebVMT cue block</a> consists of the following components, in the order given:
        </p>
        <ol>
          <li>
            A <a>WebVMT timestamp</a> representing the start time offset of the cue. The time represented by this <a>WebVMT timestamp</a> must be greater than or equal to the start time offsets of all previous cues in the file.
          </li>
          <li>
            One or more U+0020 SPACE characters or U+0009 CHARACTER TABULATION (tab) characters.
          </li>
          <li>
            The string "<code>--></code>" (U+002D HYPHEN-MINUS, U+002D HYPHEN-MINUS, U+003E GREATER-THAN SIGN).
          </li>
          <li>
            One or more U+0020 SPACE characters or U+0009 CHARACTER TABULATION (tab) characters.
          </li>
          <li>
            Optionally, a <a>WebVMT timestamp</a> representing the end time offset of the cue. The time represented by this <a>WebVMT timestamp</a> must be greater than or equal to the start time offset of the cue.
          </li>
        </ol>
        <p class='note' title='Cue Timings'>
          The <a>WebVMT cue timings</a> give the start and end offsets of the <a>WebVMT cue block</a>. Different cues can overlap. Cues are always listed ordered by their start time.
        </p>
        <p>
          A <dfn>WebVMT timestamp</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              Optionally (required if <i>hours</i> is non-zero):
              <ol>
                <li>
                  Two or more <a data-cite='HTML51/infrastructure.html#ascii-digits'>ASCII digits</a>, representing the <i>hours</i> as a base ten integer.
                </li>
                <li>
                  A U+003A COLON character (:).
                </li>
              </ol>
            </li>
            <li>
              Two <a data-cite='HTML51/infrastructure.html#ascii-digits'>ASCII digits</a>, representing the <i>minutes</i> as a base ten integer in the range 0 ≤ <i>minutes</i> ≤ 59.
            </li>
            <li>
              A U+003A COLON character (:).
            </li>
            <li>
              Two <a data-cite='HTML51/infrastructure.html#ascii-digits'>ASCII digits</a>, representing the <i>seconds</i> as a base ten integer in the range 0 ≤ <i>seconds</i> ≤ 59.
            </li>
            <li>
              A U+002E FULL STOP character (.).
            </li>
            <li>
              Three <a data-cite='HTML51/infrastructure.html#ascii-digits'>ASCII digits</a>, representing the thousandths of a second <i>seconds-frac</i> as a base ten integer.
            </li>
          </ol>
        </p>
        <p class='note' title='Timestamp Interpretation'>
          A <a>WebVMT timestamp</a> is always interpreted relative to the <a data-cite='HTML51/semantics-embedded-content.html#current-position'>current playback position</a> of the media data with which the <a>WebVMT file</a> is to be synchronized.
        </p>
        <p>
          A <dfn>WebVMT comment block</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              The string "<code>NOTE</code>" (U+004E LATIN CAPITAL LETTER N, U+004F LATIN CAPITAL LETTER O, U+0054 LATIN CAPITAL LETTER T, U+0045 LATIN CAPITAL LETTER E).
            </li>
            <li>
              Optionally, the following components, in the order given:
              <ol>
                <li>
                  Either:
                  <ul>
                    <li>
                      A U+0020 SPACE character or U+0009 CHARACTER TABULATION (tab) character.
                    </li>
                    <li>
                      A <a>WebVMT line terminator</a>.
                    </li>
                  </ul>
                </li>
                <li>
                  Any sequence of zero or more characters other than U+000A LINE FEED (LF) characters and U+000D CARRIAGE RETURN (CR) characters, each optionally separated from the next by a <a>WebVMT line terminator</a>, except that the entire resulting string must not contain the substring "<code>--></code>" (U+002D HYPHEN-MINUS, U+002D HYPHEN-MINUS, U+003E GREATER-THAN SIGN).
                </li>
              </ol>
            </li>
            <li>
              A <a>WebVMT line terminator</a>.
            </li>
          </ol>
        </p>
        <p class='note' title='Comment Parsing'>
          A <a>WebVMT comment block</a> is ignored by the parser.
        </p>
      </section>
      <section>
        <h2>WebVMT Cue Payload</h2>
        <p>
          <dfn>WebVMT metadata text</dfn> consists of any sequence of zero or more characters other than U+000A LINE FEED (LF) characters and U+000D CARRIAGE RETURN (CR) characters, each optionally separated from the next by a <a>WebVMT line terminator</a>. (In other words, any text that does not have two consecutive <a>WebVMT line terminator</a>s and does not start or end with a <a>WebVMT line terminator</a>.)
        </p>
        <p>
          The string represents a <a>WebVMT command list</a>.
        </p>
        <p>
          <a>WebVMT metadata text</a> cues are only useful for scripted applications (e.g. using the <code>metadata</code> text track <a data-cite='HTML51/semantics-embedded-content.html#kind-of-track'>kind</a> in a HTML <a data-cite='HTML51/semantics-embedded-content.html#text-tracks'>text track</a>).
        </p>
      </section>
      <section>
        <h2>WebVMT Media Settings</h2>
        <p>
          The <dfn>WebVMT media settings list</dfn> consists of zero or more of the following components, in any order, separated from each other by one or more U+0020 SPACE characters, U+0009 CHARACTER TABULATION (tab) characters, or </a>WebVMT line terminator</a>s, except that the string must not contain two consecutive <a>WebVMT line terminator</a>s. Each component must not be included more than once per <a>WebVMT media settings list</a> string.
        </p>
        <ul>
          <li>
            A <a>WebVMT media url setting</a>.
          </li>
          <li>
            A <a>WebVMT media MIME type setting</a>.
          </li>
          <li>
            A <a>WebVMT media start time setting</a>.
          </li>
          <li>
            A <a>WebVMT media path setting</a>.
          </li>
        </ul>
        <p>
          A <dfn>WebVMT media url setting</dfn> consists of the following components, in the order given:
        </p>
        <ol>
          <li>
            The string "<code>url</code>".
          </li>
          <li>
            A U+003A COLON character (:).
          </li>
          <li>
            A <a data-cite='HTML51/infrastructure.html#valid-url'>valid URL</a>.
          </li>
        </ol>
        <p class='note' title='URL Resolution'>
          For the purpose of resolving a <a data-cite='RFC3986' data-no-xref=''>URL</a> in the <code>MEDIA</code> block of a WebVMT file, or any URLs in resources referenced from <code>MEDIA</code> blocks of a WebVMT file, if the URL’s scheme is not "<code>data</code>", then the user agent must act as if the URL failed to resolve. If the <code>url</code> value does not match the <code>tileurl</code> attribute of the HTML <code>&lt;track&gt;</code> element, then the <code>tileurl</code> value takes precedence.
        </p>
        <p>
          A <dfn>WebVMT media MIME type setting</dfn> consists of the following components, in the order given:
        </p>
        <ol>
          <li>
            The string "<code>mimetype</code>".
          </li>
          <li>
            A U+003A COLON character (:).
          </li>
          <li>
            A <a data-cite='HTML51/infrastructure.html#valid-mime-type'>valid MIME type</a>.
          </li>
        </ol>
        <p>
          A <dfn>WebVMT media start time setting</dfn> consists of the following components, in the order given:
        </p>
        <ol>
          <li>
            The string "<code>starttime</code>".
          </li>
          <li>
            A U+003A COLON character (:).
          </li>
          <li>
            A <a data-cite='HTML51/infrastructure.html#valid-global-date-and-time-string'>valid global date and time string</a>.
          </li>
        </ol>
        <p>
          A <dfn>WebVMT media path setting</dfn> consists of the following components, in the order given:
        </p>
        <ol>
          <li>
            The string "<code>path</code>".
          </li>
          <li>
            A U+003A COLON character (:).
          </li>
          <li>
            A <a>WebVMT path identifier</a>.
          </li>
        </ol>
      </section>
      <section>
        <h2>WebVMT Map Settings</h2>
        <p>
          The <dfn>WebVMT map settings list</dfn> consists of the following components, in any order, separated from each other by one or more U+0020 SPACE characters, U+0009 CHARACTER TABULATION (tab) characters, or <a>WebVMT line terminator</a>s, except that the string must not contain two consecutive <a>WebVMT line terminator</a>s. Each component must be included once per <a>WebVMT map settings list</a> string.
        </p>
        <ul>
          <li>
            A <a>WebVMT map center setting</a>.
          </li>
          <li>
            A <a>WebVMT map zoom setting</a>.
          </li>
        </ul>
        <p class='note' title='Initial Map State'>
          The <a>WebVMT map settings list</a> defines the <a>WebVMT map</a> state before the first cue.
        </p>
        <p>
          A <dfn>WebVMT map center setting</dfn> consists of a <a>WebVMT location setting</a>.
        </p>
        <p>
          A <dfn>WebVMT map zoom setting</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              The string "<code>rad</code>".
            </li>
            <li>
              A U+003A COLON character (:).
            </li>
            <li>
              One or more <a data-cite='HTML51/infrastructure.html#ascii-digits'>ASCII digits</a>.
            </li>
            <li>
              Optionally:
              <ol>
                <li>
                  A U+002E DOT character (.).
                </li>
                <li>
                  One or more <a data-cite='HTML51/infrastructure.html#ascii-digits'>ASCII digits</a>.
                </li>
              </ol>
            </li>
          </ol>
        </p>
        <p class='note' title='Zoom Radius'>
          When interpreted as a number, the <a>WebVMT map zoom setting</a> represents the <a>map zoom radius</a>.
        </p>
        <p>
          A <dfn>WebVMT location setting</dfn> consists of the following components, in any order, separated from each other by a U+002C COMMA character (,). Each component must be included once per <a>WebVMT location setting</a> string.
          <ul>
            <li>
              A <a>WebVMT latitude setting</a>.
            </li>
            <li>
              A <a>WebVMT longitude setting</a>.
            </li>
          </ul>
        </p>
        <p>
          A <dfn>WebVMT latitude setting</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              The string "<code>lat</code>".
            </li>
            <li>
              A U+003A COLON character (:).
            </li>
            <li>
              A <a>WebVMT latitude</a>.
            </li>
          </ol>
        </p>
        <p>
          A <dfn>WebVMT latitude</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              Optionally, a U+002D HYPHEN-MINUS character (-).
            </li>
            <li>
              One or more <a data-cite='HTML51/infrastructure.html#ascii-digits'>ASCII digits</a>.
            </li>
            <li>
              Optionally:
              <ol>
                <li>
                  A U+002E DOT character (.).
                </li>
                <li>
                  One or more <a data-cite='HTML51/infrastructure.html#ascii-digits'>ASCII digits</a>.
                </li>
              </ol>
            </li>
          </ol>
        </p>
        <p class='note' title='Latitude Range'>
          When interpreted as a number, a <a>WebVMT latitude</a> must be in the range -90..+90.
        </p>
        <p>
          A <dfn>WebVMT longitude setting</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              The string "<code>lng</code>".
            </li>
            <li>
              A U+003A COLON character (:).
            </li>
            <li>
              A <a>WebVMT longitude</a>.
            </li>
          </ol>
        </p>
        <p>
          A <dfn>WebVMT longitude</dfn> consists of the following components, in the order given:
          <ol>
            <li>
              Optionally, a U+002D HYPHEN-MINUS character (-).
            </li>
            <li>
              One or more <a data-cite='HTML51/infrastructure.html#ascii-digits'>ASCII digits</a>.
            </li>
            <li>
              Optionally:
              <ol>
                <li>
                  A U+002E DOT character (.).
                </li>
                <li>
                  One or more <a data-cite='HTML51/infrastructure.html#ascii-digits'>ASCII digits</a>.
                </li>
              </ol>
            </li>
          </ol>
        </p>
        <p class='note' title='Longitude Range'>
          When interpreted as a number, a <a>WebVMT longitude</a> must be in the range -180..+180.
        </p>
      </section>
      <section>
        <h2>WebVMT Commands</h2>
        <p>
          A <dfn>WebVMT command list</dfn> consists of one or more of the following components in any order, separated from each other by a <a>WebVMT line terminator</a>:
          <ul>
            <li>
              A <a>WebVMT map control command</a>.
            </li>
            <li>
              A <a>WebVMT shape annotation command</a>.
            </li>
            <li>
              A <a>WebVMT path annotation command</a>.
            </li>
          </ul>
        </p>
        <section>
          <h2>WebVMT Map Commands</h2>
          <p>
            A <dfn>WebVMT map control command</dfn> consists of one of the following components:
            <ul>
              <li>
                A <a>WebVMT pan command</a>.
              </li>
              <li>
                A <a>WebVMT zoom command</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT pan command</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> representing the following <a data-cite='ECMA-404' data-no-xref=''>JSON object</a>:
            <ul>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>panto</code>".
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a>WebVMT pan parameter list</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT pan parameter list</dfn> is a <a data-cite='ECMA-404' data-no-xref=''>JSON object</a> representing the following components in any order:
            <ul>
              <li>
                A <a>WebVMT location attribute list</a>.
              </li>
              <li>
                Optionally, one of the following components:
                <ul>
                  <li>
                    A <a>WebVMT end time attribute</a>.
                  </li>
                  <li>
                    A <a>WebVMT duration attribute</a>.
                  </li>
                </ul>
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT location attribute list</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> representing a list of the following <a data-cite='ECMA-404' data-no-xref=''>JSON value</a>s in any order, separated from each other by a U+002C COMMA character (,):
            <ul>
              <li>
                A <a>WebVMT latitude attribute</a>.
              </li>
              <li>
                A <a>WebVMT longitude attribute</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT latitude attribute</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> consisting of the following components in the order given:
            <ol>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>lat</code>".
              </li>
              <li>
                A U+003A COLON character (:).
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a data-cite='ECMA-404' data-no-xref=''>JSON number</a>.
              </li>
            </ol>
          </p>
          <p class='note' title='Latitude Range'>
            When interpreted as a number, a <a>WebVMT latitude attribute</a> must be in the range -90..+90.
          </p>
          <p>
            A <dfn>WebVMT longitude attribute</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> consisting of the following components in the order given:
            <ol>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>lng</code>".
              </li>
              <li>
                A U+003A COLON character (:).
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a data-cite='ECMA-404' data-no-xref=''>JSON number</a>.
              </li>
            </ol>
          </p>
          <p class='note' title='Longitude Range'>
            When interpreted as a number, a <a>WebVMT longitude attribute</a> must be in the range -180..+180.
          </p>
          <p>
            A <dfn>WebVMT zoom command</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> representing the following <a data-cite='ECMA-404' data-no-xref=''>JSON object</a>:
            <ul>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>zoom</code>".
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a>WebVMT zoom parameter list</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT zoom parameter list</dfn> is a <a data-cite='ECMA-404' data-no-xref=''>JSON object</a> representing the following component:
            <ul>
              <li>
                A <a>WebVMT radius attribute</a>.
              </li>
            </ul>
          </p>
          <p class='note' title='Zoom Radius'>
            When interpreted as a number, the <a>WebVMT map zoom setting</a> represents the <a>map zoom radius</a>.
          </p>
          <p>
            A <dfn>WebVMT radius attribute</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> consisting of the following components in the order given:
          </p>
          <p>
            <ol>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>rad</code>".
              </li>
              <li>
                A U+003A COLON character (:).
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a data-cite='ECMA-404' data-no-xref=''>JSON number</a> greater than zero.
              </li>
            </ol>
          </p>
        </section>
        <section>
          <h2>WebVMT Shape Commands</h2>
          <p>
            A <dfn>WebVMT shape annotation command</dfn> consists of one of the following components:
            <ul>
              <li>
                A <a>WebVMT circle command</a>.
              </li>
              <li>
                A <a>WebVMT polygon command</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT circle command</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> representing the following <a data-cite='ECMA-404' data-no-xref=''>JSON object</a>:
            <ul>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>circle</code>".
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a>WebVMT circle parameter list</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT circle parameter list</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON object</a> representing the following components in any order:
            <ul>
              <li>
                A <a>WebVMT location attribute list</a>.
              </li>
              <li>
                A <a>WebVMT radius attribute</a>.
              </li>
              <li>
                Optionally, a <a>WebVMT animation subcommand</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT polygon command</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> representing the following <a data-cite='ECMA-404' data-no-xref=''>JSON object</a>:
          </p>
          <p>
            <ul>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>polygon</code>".
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a>WebVMT polygon parameter list</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT polygon parameter list</dfn> consists of the following <a data-cite='ECMA-404' data-no-xref=''>JSON object</a>:
            <ul>
              <li>
                A <a>WebVMT polygon points list</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT polygon points list</dfn> consists of the following <a data-cite='ECMA-404' data-no-xref=''>JSON object</a>:
            <ul>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>points</code>".
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a>WebVMT vertices list</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT vertices list</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON array</a> of three or more <a data-cite='ECMA-404' data-no-xref=''>JSON object</a>s each representing the following components in any order:
            <ul>
              <li>
                A <a>WebVMT location attribute list</a>.
              </li>
              <li>
                Optionally, a <a>WebVMT animation subcommand</a>.
              </li>
            </ul>
          </p>
        </section>
        <section>
          <h2>WebVMT Path Commands</h2>
          <p>
            A <dfn>WebVMT path annotation command</dfn> consists of one of the following components:
            <ul>
              <li>
                A <a>WebVMT move command</a>.
              </li>
              <li>
                A <a>WebVMT line command</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT move command</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> representing the following <a data-cite='ECMA-404' data-no-xref=''>JSON object</a>:
            <ul>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>moveto</code>".
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a>WebVMT move parameter list</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT move parameter list</dfn> is a <a data-cite='ECMA-404' data-no-xref=''>JSON object</a> representing the following components in any order:
            <ul>
              <li>
                A <a>WebVMT location attribute list</a>.
              </li>
              <li>
                Optionally, a <a>WebVMT path attribute</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT path attribute</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> consisting of the following components in the order given:
            <ol>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>path</code>".
              </li>
              <li>
                A U+003A COLON character (:).
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> representing a <a>WebVMT path identifier</a>.
              </li>
            </ol>
          </p>
          <p>
            A <dfn>WebVMT line command</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> representing the following <a data-cite='ECMA-404' data-no-xref=''>JSON object</a>:
            <ul>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>lineto</code>".
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a>WebVMT line parameter list</a>.
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT line parameter list</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON object</a> representing the following components in any order:
            <ul>
              <li>
                A <a>WebVMT location attribute list</a>.
              </li>
              <li>
                Optionally, a <a>WebVMT path attribute</a>.
              </li>
              <li>
                Optionally, one of the following components:
                <ul>
                  <li>
                    A <a>WebVMT end time attribute</a>.
                  </li>
                  <li>
                    A <a>WebVMT duration attribute</a>.
                  </li>
                </ul>
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT path identifier</dfn> is any sequence of one or more characters not containing the substring "-->" (U+002D HYPHEN-MINUS, U+002D HYPHEN-MINUS, U+003E GREATER-THAN SIGN), nor containing any U+000A LINE FEED (LF) characters or U+000D CARRIAGE RETURN (CR) characters.
          </p>
          <p class='note' title='Path Identification'>
            A <a>WebVMT path identifier</a> is a string which uniquely identifies a moving object in the <a>WebVMT file</a>, for example a camera.
          </p>
        </section>
        <section>
          <h2>WebVMT Animation Subcommand</h2>
          <p>
            A <dfn>WebVMT animation subcommand</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> representing the following <a data-cite='ECMA-404' data-no-xref=''>JSON object</a>:
            <ul>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>animate</code>".
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a>WebVMT animation parameter list</a>.
              </li>
            </ul>
          </p>
          <p class='note' title='Parent Command'>
            The <a>WebVMT animation subcommand</a> refers to the attributes of its parent command. The parent command is the <a>animation object</a>.
          </p>
          <p>
            A <dfn>WebVMT animation parameter list</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON array</a> of one or more <a>WebVMT individual animation list</a>s.
          </p>
          <p>
            A <dfn>WebVMT individual animation list</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON object</a> consisting of the following components in any order:
            <ul>
              <li>
                A <a>WebVMT name attribute</a>.
              </li>
              <li>
                A <a>WebVMT target value attribute</a>.
              </li>
              <li>
                One of the following components:
                <ul>
                  <li>
                    A <a>WebVMT end time attribute</a>.
                  </li>
                  <li>
                    A <a>WebVMT duration attribute</a>.
                  </li>
                </ul>
              </li>
            </ul>
          </p>
          <p>
            A <dfn>WebVMT name attribute</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> consisting of the following components in the order given:
            <ol>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>name</code>".
              </li>
              <li>
                A U+003A COLON character (:).
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a> consisting of a <a data-cite='ECMA-404' data-no-xref=''>JSON string</a>.
              </li>
            </ol>
          </p>
          <p class='note' title='Animation Name'>
            A <a>WebVMT name attribute</a> represents the name of the <a>animation attribute</a>.
          </p>
          <p>
            A <dfn>WebVMT target value attribute</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> consisting of the following components in the order given:
            <ol>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>to</code>".
              </li>
              <li>
                A U+003A COLON character (:).
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON value</a>.
              </li>
            </ol>
          </p>
          <p class='note' title='Animation Target Value'>
            The <a>WebVMT target value attribute</a> represents the value of the <a>animation end value</a>.
          </p>
          <p>
            A <dfn>WebVMT end time attribute</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> consisting of the following components in the order given:
            <ol>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>end</code>".
              </li>
              <li>
                A U+003A COLON character (:).
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> representing a <a>WebVMT timestamp</a>.
              </li>
            </ol>
          </p>
          <p class='note' title='Animation End Time'>
            A <a>WebVMT end time attribute</a> represents the value of the <a>animation end time</a>.
          </p>
          <p>
            A <dfn>WebVMT duration attribute</dfn> consists of a <a data-cite='ECMA-404' data-no-xref=''>JSON text</a> consisting of the following components in the order given:
            <ol>
              <li>
                The <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> "<code>dur</code>".
              </li>
              <li>
                A U+003A COLON character (:).
              </li>
              <li>
                A <a data-cite='ECMA-404' data-no-xref=''>JSON string</a> representing a <a>WebVMT timestamp</a>.
              </li>
            </ol>
          </p>
          <p class='note' title='Animation Duration'>
            A <a>WebVMT duration attribute</a> represents the difference in value between the <a>animation end time</a> and the <a>animation start time</a>.
          </p>
        </section>
      </section>
      <section>
        <h2>Properties Of Cue Sequences</h2>
        <section>
          <h2>WebVMT File Using Only Nested Cues</h2>
          <p>
            A <a>WebVMT file</a> whose cues all comply with the following rule is said to be a <dfn>WebVMT file using only nested cues</dfn>.
          </p>
          <p>
            Given any two cues <i>cue1</i> and <i>cue2</i> with start and end time offsets <i>(x1, y1)</i> and <i>(x2, y2)</i> respectively:
            <ul>
              <li>
                either <i>cue1</i> lies fully within <i>cue2</i>, i.e. <i>x1 >= x2</i> and <i>y1 <= y2</i>;
              </li>
              <li>
                or <i>cue1</i> fully contains <i>cue2</i>, i.e. <i>x1 <= x2</i> and <i>y1 >= y2</i>.
              </li>
            </ul>
          </p>
          <p>
            The following example matches this definition:
          </p>
          <pre class='nohighlight example' title='Nested Cues'>
WEBVMT

NOTE Required non-cue blocks omitted for clarity

00:00.000 --> 01:24.000
{ "circle": { "lat": 0, "lng": 0, "rad": 2000 } }

00:00.000 --> 00:44.000
{ "moveto": { "lat": 0, "lng": 0, "path": "cam1" } }
{ "lineto": { "lat": 0.12, "lng": 0.34, "path": "cam1" } }

00:44.000 --> 01:19.000
{ "lineto": { "lat": 0.56, "lng": 0.78, "path": "cam1" } }

01:24.000 --> 05:00.000
{ "circle": { "lat": 0, "lng": 0, "rad": 30000 } }

01:35.000 --> 03:00.000
{ "moveto": { "lat": 0.87, "lng": 0.65, "path": "cam2" } }
{ "lineto": { "lat": 0.43, "lng": 0.21, "path": "cam2" } }

03:00.000 --> 05:00.000
{ "lineto": { "lat": 0, "lng": 0, "path": "cam2" } }
          </pre>
          <p>
            Notice how you can express the cues in this WebVMT file as a tree structure:
          </p>
          <ul>
            <li>
              2km Circle at (0, 0)
              <ul>
                <li>
                  Line (0, 0) to (0.12, 0.34)
                </li>
                <li>
                  Line (0.12, 0.34) to (0.56, 0.78)
                </li>
              </ul>
            </li>
            <li>
              30km Circle at (0, 0)
              <ul>
                <li>
                  Line (0.87, 0.65) to (0.43, 0.21)
                </li>
                <li>
                  Line (0.43, 0.21) to (0, 0)
                </li>
              </ul>
            </li>
          </ul>
          <p>
            If the file has cues that can’t be expressed in this fashion, then they don’t match the definition of a <a>WebVMT file using only nested cues</a>. For example:
          </p>
          <pre class='nohighlight example' title='Non-Nested Cues'>
WEBVMT

NOTE Required non-cue blocks omitted for clarity

00:00.000 --> 01:00.000
{ "moveto": { "lat": 0.12, "lng": 0.34, "path": "cam3" } }
{ "lineto": { "lat": 0.56, "lng": 0.78, "path": "cam3" } }

00:30.000 --> 01:30.000
{ "moveto": { "lat": 0.87, "lng": 0.65, "path": "cam4" } }
{ "lineto": { "lat": 0.43, "lng": 0.21, "path": "cam4" } }
          </pre>
          <p>
            In this ninety-second example, the two cues partly overlap, with the first ending before the second ends and the second starting before the first ends. This therefore is not a <a>WebVMT file using only nested cues</a>.
          </p>
        </section>
      </section>
    </section>
    <section class='informative' id='knownissues'>
      <h2>Known Issues</h2>
      <p>
        This section captures issues which have been identified, but are not fully documented in this explanatory specification.
      </p>
      <p class='ednote'>
        As the specification develops, issues will be moved out of this section and included elsewhere in the document, until it is no longer needed and is completely removed.
      </p>
      <section id='plannedfeatures'>
        <h2>Planned Features</h2>
        <p>
          This section lists potential features which have been identified during the development process, but have not yet matured to a full design specification.
        </p>
        <p class='note'>
          Features which appear in this section warrant further investigation, but are not guaranteed to appear in the final specification.
        </p>
        <section id='marker'>
          <h2>Markers</h2>
          <p>
            An image linked to and displayed at an offset from a geolocation.
          </p>
        </section>
        <section id='label'>
          <h2>Labels</h2>
          <p>
            A text string linked to and displayed at an offset from a geolocation.
          </p>
        </section>
        <section id='tileshortcut'>
          <h2>Tile Shortcuts</h2>
          <p>
            Shortcuts to popular tile URLs for easy access and to help avoid URL syntax errors.
          </p>
        </section>
        <section id='layer'>
          <h2>Layers</h2>
          <p>
            Syntax to allow more than one layer of map tiles to be specified, e.g. 'map' and 'satellite' layers.
          </p>
          <p>
            This should be functional, but remain lightweight.
          </p>
        </section>
        <section id='multipleapis'>
          <h2>Multiple APIs</h2>
          <p>
            The current tech demo is based on the Leaflet API, but should be broadened to support other web map APIs, e.g. Open Layers.
          </p>
          <p>
            A hot-swap feature would allow users to switch API on-the-fly to take advantage of the unique features supported by different APIs, e.g. Street View.
          </p>
        </section>
        <section id='cameradirection'>
          <h2>Camera Direction</h2>
          <p>
            Camera orientation may not match the direction of travel, or may be dynamic, e.g. for Augmented Reality. Field of view and zoom level also affect video frame content and may vary over time.
          </p>
        </section>
        <section id='datasync'>
          <h2>Data Sync</h2>
          <p>
            Mobile video devices often collect additional data, e.g. drones can be used as sensor platforms and dashcams record vehicle telemetry such as speed and acceleration.
          </p>
          <p>
            Allowing the option to embed JSON data within cues would permit synchronisation of arbitrary data with location and video without compromising interoperability, in a similar fashion to the GPX <code>&lt;extension&gt;</code> element.
          </p>
        </section>
        <section id='coordrefsys'>
          <h2>Co-ordinate Reference Systems</h2>
          <p>
            Although originally conceived for Earth-based use, spatial data in other environments could be accommodated by specifying the co-ordinate reference system. For example, location on another planet, e.g. Mars, or in an artifical environment, e.g. a video game.
          </p>
        </section>
        <section id='movingobjects'>
          <h2>Moving Objects</h2>
          <p>
            <a>WebVMT paths</a> represent objects moving through the mapped space, though could be extended to support properties associated with motion such as distance travelled, speed, heading, etc. through a defined API.
          </p>
          <p>
            Care should be taken to build a lightweight interface which includes simple, common properties that are useful to most use cases and avoids overloading with unnecessary edge cases, processing overheads and complexity.
          </p>
        </section>
        <section id='interpolation'>
          <h2>Interpolation</h2>
          <p>
            Sensor data could be interpolated between sample points to provide intermediate values where necessary, while retaining the source data sample values.
          </p>
          <p>
            Proposed interpolation schemes include:
            <ul>
              <li>Step: values remain constant until the next sample time, e.g. vehicle gear selection;</li>
              <li>Linear: values are linearly interpolated to the next sample time, e.g. temperature;</li>
              <li>Discrete: values are only valid instanteously at a sample time, e.g. headcount in a video frame.</li>
            </ul>
          </p>
          <p>
            An interpolation command could replace the <a>WebVMT animation subcommand</a> which is a specific example of the more general case and could incorporate identified design improvements.
          </p>
        </section>
        <section id='3dcoords'>
          <h2>3D Co-ordinates</h2>
          <p>
            <a>WebVMT locations</a> could be expanded to (optionally) include a third co-ordinate representing height. Omitting height would allow backward compatibility with 2D coordinates.
          </p>
          <p>
            Height could be referenced either from ground level, e.g. for the top of a structure, or from mean sea level, e.g. for an aircraft.
          </p>
        </section>
      </section>
      <section id='plannedinterfaces'>
        <h2>Planned Interfaces</h2>
        <p>
          This section lists interfaces which have been identified during the development process, but have not yet matured to a full design specification.
        </p>
        <section id='cueinterface'>
          <h2>VMTCue Interface</h2>
          <p>
            Expose WebVMT Cues in the DOM API, based on the <a data-cite='HTML51/semantics-embedded-content.html#datacue-datacue'>HTML5 DataCue interface</a>. For example:
            <pre class='nohighlight' title='WebVMT Cue Interface'>
              [Exposed=Window,
              Constructor(double startTime, double endTime, DOMString text),
              Constructor(double startTime, DOMString text)]
              interface VMTCue : DataCue {
                attribute unrestricted double endTime;
              };
            </pre>
          </p>
          <p>
            This is analogous to the <a data-cite='WEBVTT#the-vttcue-interface'>VTTCue</a> interface.
          </p>
        </section>
        <section id='mapinterface'>
          <h2>VMTMap Interface</h2>
          <p>
            Expose WebVMT Maps in the DOM API. For example:
            <pre class='nohighlight' title='WebVMT Map Interface'>
              [Exposed=Window,
              Constructor]
              interface VMTMap {
                attribute double centerLat;
                attribute double centerLng;
                attribute double zoomRad;
                attribute object getMap;
              };
            </pre>
          </p>
          <p>
            This is analogous to the <a data-cite='WEBVTT#the-vttregion-interface'>VTTRegion</a> interface.
          </p>
        </section>
      </section>
    </section>
  </body>
</html>
